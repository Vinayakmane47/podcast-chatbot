{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"), HumanMessage(content=\"I don't like eating tasty things\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./bella_vista.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './bella_vista.txt'}, page_content=\"Q: What are the hours of operation for Bella Vista?\\nA: Bella Vista is open from 11 a.m. to 11 p.m. from Monday to Saturday. On Sundays, we welcome guests from 12 p.m. to 10 p.m.\\n\\nQ: What type of cuisine does Bella Vista serve?\\nA: Bella Vista offers a delightful blend of Mediterranean and contemporary American cuisine. We pride ourselves on using the freshest ingredients, many of which are sourced locally.\\n\\nQ: Do you offer vegetarian or vegan options at Bella Vista?\\nA: Absolutely! Bella Vista boasts a diverse menu that includes a variety of vegetarian and vegan dishes. Our chefs are also happy to customize dishes based on dietary needs.\\n\\nQ: Is Bella Vista family-friendly?\\nA: Yes, Bella Vista is a family-friendly establishment. We have a dedicated kids' menu and offer high chairs and booster seats for our younger guests.\\n\\nQ: Can I book private events at Bella Vista?\\nA: Certainly! Bella Vista has a private dining area perfect for events, parties, or corporate gatherings. We also offer catering services for off-site events.\\n\\nQ: What's the ambiance like at Bella Vista?\\nA: Bella Vista boasts a cozy and elegant setting, with ambient lighting, comfortable seating, and a stunning view of the city skyline. Whether you're looking for a romantic dinner or a casual meal with friends, Bella Vista provides the perfect atmosphere.\\n\\nQ: Do I need a reservation for Bella Vista?\\nA: While walk-ins are always welcome, we recommend making a reservation, especially during weekends and holidays, to ensure a seamless dining experience.\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'audio.wav'}, page_content='In this podcast, the speakers discuss the pressing issue of the environment and the need for immediate attention. Speaker_1 emphasizes the importance of reducing carbon emissions and investing in renewable energy. Speaker_2 adds that while renewable energy is crucial, we must also prioritize conserving natural habitats and protecting wildlife from the effects of climate change. Speaker_1 agrees with both points but highlights the importance of considering the economic impact of environmental policies. They stress the need for solutions that balance ecological preservation with economic growth. Overall, the speakers advocate for a holistic approach to addressing environmental challenges.')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "test = \"In this podcast, the speakers discuss the pressing issue of the environment and the need for immediate attention. Speaker_1 emphasizes the importance of reducing carbon emissions and investing in renewable energy. Speaker_2 adds that while renewable energy is crucial, we must also prioritize conserving natural habitats and protecting wildlife from the effects of climate change. Speaker_1 agrees with both points but highlights the importance of considering the economic impact of environmental policies. They stress the need for solutions that balance ecological preservation with economic growth. Overall, the speakers advocate for a holistic approach to addressing environmental challenges.\"\n",
    "document = Document(\n",
    "    page_content= test,\n",
    "    metadata={\"source\": \"audio.wav\"}\n",
    ")\n",
    "\n",
    "document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'audio.wav'}, page_content='In this podcast, the speakers discuss the pressing issue of the environment and the need for'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='and the need for immediate attention. Speaker_1 emphasizes the importance of reducing carbon'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='of reducing carbon emissions and investing in renewable energy. Speaker_2 adds that while renewable'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='while renewable energy is crucial, we must also prioritize conserving natural habitats and'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='habitats and protecting wildlife from the effects of climate change. Speaker_1 agrees with both'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='agrees with both points but highlights the importance of considering the economic impact of'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='economic impact of environmental policies. They stress the need for solutions that balance'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='that balance ecological preservation with economic growth. Overall, the speakers advocate for a'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='advocate for a holistic approach to addressing environmental challenges.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "documents = text_splitter.split_documents([document])\n",
    "documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x10edbee30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "\n",
    "db=FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'audio.wav'}, page_content='of reducing carbon emissions and investing in renewable energy. Speaker_2 adds that while renewable'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='while renewable energy is crucial, we must also prioritize conserving natural habitats and'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='and the need for immediate attention. Speaker_1 emphasizes the importance of reducing carbon'),\n",
       " Document(metadata={'source': 'audio.wav'}, page_content='advocate for a holistic approach to addressing environmental challenges.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"renewable energy is important \"\n",
    "result=db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template='\\nAnswer the following question based only on the provided context. \\nThink step by step before providing a detailed answer. \\nI will tip you $1000 if the user finds the answer helpful. \\n<context>\\n{context}\\n</context>\\nQuestion: {input}'))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Design ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction\n",
    "## Create Stuff Docment Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x10edbee30>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"why  is renewable energy important ? \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'why  is renewable energy important ? ',\n",
       " 'context': [Document(metadata={'source': 'audio.wav'}, page_content='of reducing carbon emissions and investing in renewable energy. Speaker_2 adds that while renewable'),\n",
       "  Document(metadata={'source': 'audio.wav'}, page_content='while renewable energy is crucial, we must also prioritize conserving natural habitats and'),\n",
       "  Document(metadata={'source': 'audio.wav'}, page_content='and the need for immediate attention. Speaker_1 emphasizes the importance of reducing carbon'),\n",
       "  Document(metadata={'source': 'audio.wav'}, page_content='advocate for a holistic approach to addressing environmental challenges.')],\n",
       " 'answer': 'Renewable energy is important because it helps reduce carbon emissions, which in turn helps combat climate change and its negative effects on the environment. Additionally, investing in renewable energy sources helps to decrease our reliance on fossil fuels, which are finite resources with harmful environmental impacts. By prioritizing renewable energy, we can work towards a more sustainable future and address environmental challenges in a holistic manner.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.0s stop=3.8s speaker_SPEAKER_01\n",
      "start=4.0s stop=7.8s speaker_SPEAKER_01\n",
      "start=9.1s stop=14.5s speaker_SPEAKER_00\n",
      "start=14.8s stop=17.6s speaker_SPEAKER_00\n",
      "start=19.1s stop=20.4s speaker_SPEAKER_02\n",
      "start=20.7s stop=24.6s speaker_SPEAKER_02\n",
      "start=25.0s stop=29.2s speaker_SPEAKER_02\n",
      "Time taken by algo is 3.493901014328003\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "pipeline.to(torch.device(\"mps\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"/Users/vinayak/AI/projects/voice-assistant-bot/environment_debate.wav\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0\n",
    "\n",
    "# ...\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken by algo is {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '1272-128104-0000.flac',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "        0.0010376 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "The environment is a pressing issue that requires immediate attention. We need to reduce carbon emissions and invest in renewable energy. While renewable energy is important, we also need to focus on conserving natural habitats and protecting wildlife from the effects of climate change. I agree with both points, but we must also consider the economic impact of environmental policies.\n",
      "final time : 23.406076192855835\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"/Users/vinayak/AI/projects/voice-assistant-bot/environment_debate.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)\n",
    "\n",
    "print(f\"final time : {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 480/480 [00:00<00:00, 2.35MB/s]\n",
      "Downloading data: 100%|██████████| 1.98M/1.98M [00:01<00:00, 1.87MB/s]\n",
      "Generating validation split: 100%|██████████| 1/1 [00:00<00:00, 43.53 examples/s]\n",
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequences': tensor([[50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "           262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "           465, 21443,    13, 50687, 50687,  5414,   318,  1770,    13,  2264,\n",
      "           346,   353,   338,  5642,  1342,  3499,   621,   465,  2300,    13,\n",
      "         50927, 50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,\n",
      "           286,   262,   614,    11,   351,  6786,   290, 32595, 12023, 28236,\n",
      "         51205, 51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,\n",
      "           290,   663,  2482,  3051,   749, 14704,   284,   262,  2000,    13,\n",
      "         51551, 50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,\n",
      "          1122,   338,   670,   318,  1107,  8312,   706,   477,    11,   290,\n",
      "         50647, 50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,\n",
      "           314,   400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,\n",
      "           389,   257,  3297,   286,   510,    12,    70,  1371,   290, 22037,\n",
      "         21641,    11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,\n",
      "           389,   355,  2260,   355,   257,   474, 32735, 21247,    13, 51411,\n",
      "         51411,  1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,\n",
      "           530,   881,   287,   262,   976,   835,   326,  1770,    13,  1879,\n",
      "          6122,   973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823,\n",
      "         50363,  1770,    13,  1757,  7778,   959,  3607,   465,  1650,   353,\n",
      "           257, 37999, 23905,   287,   262,   736,    13, 50597, 50597,  7413,\n",
      "           339,  1139,    11,   588,   257, 47259,   263,   290,   257,  9663,\n",
      "          7837,    11,  1306,   582,    13, 50815]]), 'segments': [[{'start': tensor(0.), 'end': tensor(6.4800), 'tokens': tensor([50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "          262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "          465, 21443,    13, 50687]), 'result': tensor([50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "          262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "          465, 21443,    13, 50687, 50687,  5414,   318,  1770,    13,  2264,\n",
      "          346,   353,   338,  5642,  1342,  3499,   621,   465,  2300,    13,\n",
      "        50927, 50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,\n",
      "          286,   262,   614,    11,   351,  6786,   290, 32595, 12023, 28236,\n",
      "        51205, 51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,\n",
      "          290,   663,  2482,  3051,   749, 14704,   284,   262,  2000,    13,\n",
      "        51551, 51551, 50256])}, {'start': tensor(6.4800), 'end': tensor(11.2800), 'tokens': tensor([50687,  5414,   318,  1770,    13,  2264,   346,   353,   338,  5642,\n",
      "         1342,  3499,   621,   465,  2300,    13, 50927]), 'result': tensor([50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "          262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "          465, 21443,    13, 50687, 50687,  5414,   318,  1770,    13,  2264,\n",
      "          346,   353,   338,  5642,  1342,  3499,   621,   465,  2300,    13,\n",
      "        50927, 50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,\n",
      "          286,   262,   614,    11,   351,  6786,   290, 32595, 12023, 28236,\n",
      "        51205, 51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,\n",
      "          290,   663,  2482,  3051,   749, 14704,   284,   262,  2000,    13,\n",
      "        51551, 51551, 50256])}, {'start': tensor(11.2800), 'end': tensor(16.8400), 'tokens': tensor([50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,   286,\n",
      "          262,   614,    11,   351,  6786,   290, 32595, 12023, 28236, 51205]), 'result': tensor([50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "          262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "          465, 21443,    13, 50687, 50687,  5414,   318,  1770,    13,  2264,\n",
      "          346,   353,   338,  5642,  1342,  3499,   621,   465,  2300,    13,\n",
      "        50927, 50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,\n",
      "          286,   262,   614,    11,   351,  6786,   290, 32595, 12023, 28236,\n",
      "        51205, 51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,\n",
      "          290,   663,  2482,  3051,   749, 14704,   284,   262,  2000,    13,\n",
      "        51551, 51551, 50256])}, {'start': tensor(16.8400), 'end': tensor(23.7600), 'tokens': tensor([51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,   290,\n",
      "          663,  2482,  3051,   749, 14704,   284,   262,  2000,    13, 51551]), 'result': tensor([50363,  1770,    13,  2264,   346,   353,   318,   262, 46329,   286,\n",
      "          262,  3504,  6097,    11,   290,   356,   389,  9675,   284,  7062,\n",
      "          465, 21443,    13, 50687, 50687,  5414,   318,  1770,    13,  2264,\n",
      "          346,   353,   338,  5642,  1342,  3499,   621,   465,  2300,    13,\n",
      "        50927, 50927,   679,  4952,   514,   326,   379,   428, 43856,  1622,\n",
      "          286,   262,   614,    11,   351,  6786,   290, 32595, 12023, 28236,\n",
      "        51205, 51205,   878,   514,    11,   985,  2915,  7428,   422,  6600,\n",
      "          290,   663,  2482,  3051,   749, 14704,   284,   262,  2000,    13,\n",
      "        51551, 51551, 50256])}, {'start': tensor(23.7600), 'end': tensor(29.4400), 'tokens': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(29.4400), 'end': tensor(33.7600), 'tokens': tensor([50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(33.7600), 'end': tensor(39.8000), 'tokens': tensor([50863,  5164, 10076,   338,  5986,   389,   257,  3297,   286,   510,\n",
      "           12,    70,  1371,   290, 22037, 21641,    11,   290, 14737,   338,\n",
      "        40123, 51165]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(39.8000), 'end': tensor(44.7200), 'tokens': tensor([51165,  4686,   829,   389,   355,  2260,   355,   257,   474, 32735,\n",
      "        21247,    13, 51411]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(44.7200), 'end': tensor(50.3600), 'tokens': tensor([51411,  1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,\n",
      "          530,   881,   287,   262,   976,   835,   326,  1770,    13,  1879,\n",
      "         6122,   973, 51693]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(50.3600), 'end': tensor(52.9600), 'tokens': tensor([51693,   284,  7644,   465,  9941,    13, 51823]), 'result': tensor([50363,   679,   468, 12296, 17188,  1771,  7361, 26113, 18881,  1122,\n",
      "          338,   670,   318,  1107,  8312,   706,   477,    11,   290, 50647,\n",
      "        50647,   460,  7073,   287,   340,   475,  1310,   286, 26898,   314,\n",
      "          400, 22260,    13, 50863, 50863,  5164, 10076,   338,  5986,   389,\n",
      "          257,  3297,   286,   510,    12,    70,  1371,   290, 22037, 21641,\n",
      "           11,   290, 14737,   338, 40123, 51165, 51165,  4686,   829,   389,\n",
      "          355,  2260,   355,   257,   474, 32735, 21247,    13, 51411, 51411,\n",
      "         1770,    13, 37940,  3087, 18489,   338, 32964,  8212,   379,   530,\n",
      "          881,   287,   262,   976,   835,   326,  1770,    13,  1879,  6122,\n",
      "          973, 51693, 51693,   284,  7644,   465,  9941,    13, 51823, 51823,\n",
      "        50256])}, {'start': tensor(52.9600), 'end': tensor(57.6400), 'tokens': tensor([50363,  1770,    13,  1757,  7778,   959,  3607,   465,  1650,   353,\n",
      "          257, 37999, 23905,   287,   262,   736,    13, 50597]), 'result': tensor([50363,  1770,    13,  1757,  7778,   959,  3607,   465,  1650,   353,\n",
      "          257, 37999, 23905,   287,   262,   736,    13, 50597, 50597,  7413,\n",
      "          339,  1139,    11,   588,   257, 47259,   263,   290,   257,  9663,\n",
      "         7837,    11,  1306,   582,    13, 50815, 50256])}, {'start': tensor(57.6400), 'end': tensor(62.), 'tokens': tensor([50597,  7413,   339,  1139,    11,   588,   257, 47259,   263,   290,\n",
      "          257,  9663,  7837,    11,  1306,   582,    13, 50815]), 'result': tensor([50363,  1770,    13,  1757,  7778,   959,  3607,   465,  1650,   353,\n",
      "          257, 37999, 23905,   287,   262,   736,    13, 50597, 50597,  7413,\n",
      "          339,  1139,    11,   588,   257, 47259,   263,   290,   257,  9663,\n",
      "         7837,    11,  1306,   582,    13, 50815, 50256])}]]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(16_000))\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "inputs = processor(sample[\"audio\"][\"array\"], padding=True, truncation=False, return_attention_mask=True, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, return_segments=True)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./podcast/lib/python3.10/site-packages (0.32.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in ./podcast/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./podcast/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in ./podcast/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./podcast/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./podcast/lib/python3.10/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub in ./podcast/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./podcast/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./podcast/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: requests in ./podcast/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./podcast/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./podcast/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./podcast/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./podcast/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./podcast/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./podcast/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./podcast/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
